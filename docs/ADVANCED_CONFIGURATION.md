# GitHub ç½‘ç»œç‰ˆ yt-dlp Web - é«˜çº§é…ç½®æŒ‡å—

## ğŸ”§ é«˜çº§é…ç½®

### å¤šç¯å¢ƒéƒ¨ç½²

#### 1. å¼€å‘ç¯å¢ƒé…ç½®

```bash
# .env.development
ENVIRONMENT=development
YTDLP_SOURCE=local
DEBUG=true
LOG_LEVEL=DEBUG
WEB_PORT=8080

# å¯åŠ¨å¼€å‘ç¯å¢ƒ
ENVIRONMENT=development ./build-github.sh --source local --no-cache
```

#### 2. ç”Ÿäº§ç¯å¢ƒé…ç½®

```bash
# .env.production
ENVIRONMENT=production
YTDLP_SOURCE=github_release
YTDLP_VERSION=2024.12.13  # é”å®šç‰ˆæœ¬
DEBUG=false
LOG_LEVEL=INFO
WEB_PORT=80

# å¯åŠ¨ç”Ÿäº§ç¯å¢ƒ
ENVIRONMENT=production ./build-github.sh --source github_release --push
```

#### 3. æµ‹è¯•ç¯å¢ƒé…ç½®

```bash
# .env.testing
ENVIRONMENT=testing
YTDLP_SOURCE=pypi
YTDLP_VERSION=">=2024.12.13"
DEBUG=false
LOG_LEVEL=WARNING
WEB_PORT=8080

# å¯åŠ¨æµ‹è¯•ç¯å¢ƒ
ENVIRONMENT=testing ./build-github.sh --source pypi --test
```

### è‡ªå®šä¹‰ yt-dlp æº

#### 1. æ·»åŠ è‡ªå®šä¹‰ GitHub ä»“åº“

ç¼–è¾‘ `config/ytdlp-source.yml`:

```yaml
ytdlp_source:
  # è‡ªå®šä¹‰ GitHub æº
  custom_github:
    enabled: true
    repository: "your-username/yt-dlp-fork"
    branch: "custom-features"
    version: "latest"
  
  # æ›´æ–°ä¼˜å…ˆçº§
build_strategy:
  priority:
    - "custom_github"
    - "github_release"
    - "pypi"
    - "local"
```

#### 2. ä½¿ç”¨ç§æœ‰ä»“åº“

```yaml
ytdlp_source:
  private_github:
    enabled: true
    repository: "private-org/yt-dlp-enterprise"
    token: "${GITHUB_TOKEN}"  # ç¯å¢ƒå˜é‡
    version: "v2024.12.13-enterprise"
```

#### 3. æœ¬åœ°å¼€å‘ç‰ˆæœ¬

```yaml
ytdlp_source:
  local_dev:
    enabled: true
    path: "/path/to/your/yt-dlp-dev"
    requirements: "/path/to/custom-requirements.txt"
```

### æ€§èƒ½ä¼˜åŒ–

#### 1. å¹¶å‘ä¸‹è½½é…ç½®

```python
# webapp/core/ytdlp_manager.py
def get_enhanced_options(self):
    return {
        'concurrent_fragment_downloads': 4,
        'max_downloads': 3,
        'socket_timeout': 30,
        'retries': 3,
    }
```

#### 2. ç¼“å­˜é…ç½®

```yaml
# config/ytdlp-source.yml
build_strategy:
  cache:
    enabled: true
    directory: "/app/cache/ytdlp"
    ttl_hours: 168  # 7å¤©
    max_size_mb: 1024  # 1GB
```

#### 3. å†…å­˜ä¼˜åŒ–

```yaml
# docker-compose.github.yml
services:
  yt-dlp-web-github:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'
```

### å®‰å…¨é…ç½®

#### 1. HTTPS é…ç½®

```yaml
# docker-compose.github.yml
services:
  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - yt-dlp-web-github

  yt-dlp-web-github:
    expose:
      - "8080"
    # ä¸ç›´æ¥æš´éœ²ç«¯å£
```

#### 2. åå‘ä»£ç†é…ç½®

```nginx
# nginx.conf
server {
    listen 443 ssl;
    server_name your-domain.com;
    
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    
    location / {
        proxy_pass http://yt-dlp-web-github:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

#### 3. é˜²ç«å¢™é…ç½®

```bash
# UFW é…ç½®
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 80/tcp    # HTTP
sudo ufw allow 443/tcp   # HTTPS
sudo ufw deny 8080/tcp   # ç¦æ­¢ç›´æ¥è®¿é—®åº”ç”¨ç«¯å£
sudo ufw enable
```

### ç›‘æ§å’Œæ—¥å¿—

#### 1. Prometheus ç›‘æ§

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'yt-dlp-web'
    static_configs:
      - targets: ['yt-dlp-web-github:8080']
    metrics_path: '/metrics'
    scrape_interval: 30s
```

#### 2. Grafana ä»ªè¡¨æ¿

```yaml
# docker-compose.monitoring.yml
services:
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
```

#### 3. æ—¥å¿—èšåˆ

```yaml
# docker-compose.logging.yml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
    environment:
      - discovery.type=single-node
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:7.15.0
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline

  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
```

## ğŸ”„ ç»´æŠ¤æ›´æ–°

### è‡ªåŠ¨æ›´æ–°

#### 1. å®šæ—¶æ›´æ–°è„šæœ¬

```bash
#!/bin/bash
# auto-update.sh

# æ£€æŸ¥æ–°ç‰ˆæœ¬
LATEST_VERSION=$(curl -s https://api.github.com/repos/yt-dlp/yt-dlp/releases/latest | jq -r .tag_name)
CURRENT_VERSION=$(docker exec yt-dlp-web-github python -c "import yt_dlp; print(yt_dlp.__version__)" 2>/dev/null || echo "unknown")

if [ "$LATEST_VERSION" != "$CURRENT_VERSION" ]; then
    echo "å‘ç°æ–°ç‰ˆæœ¬: $LATEST_VERSION (å½“å‰: $CURRENT_VERSION)"
    
    # å¤‡ä»½å½“å‰ç‰ˆæœ¬
    docker commit yt-dlp-web-github yt-dlp-web:backup-$(date +%Y%m%d)
    
    # æ›´æ–°
    YTDLP_VERSION=$LATEST_VERSION ./build-github.sh --no-cache
    
    # é‡å¯æœåŠ¡
    docker-compose -f docker-compose.github.yml up -d
    
    echo "æ›´æ–°å®Œæˆ"
else
    echo "å·²æ˜¯æœ€æ–°ç‰ˆæœ¬: $CURRENT_VERSION"
fi
```

#### 2. Cron å®šæ—¶ä»»åŠ¡

```bash
# æ·»åŠ åˆ° crontab
0 2 * * 0 /path/to/auto-update.sh >> /var/log/yt-dlp-update.log 2>&1
```

### å¤‡ä»½æ¢å¤

#### 1. æ•°æ®å¤‡ä»½

```bash
#!/bin/bash
# backup.sh

BACKUP_DIR="/backup/yt-dlp/$(date +%Y%m%d)"
mkdir -p "$BACKUP_DIR"

# å¤‡ä»½ä¸‹è½½æ–‡ä»¶
docker run --rm \
  -v yt-dlp-web-deploy_downloads:/data \
  -v "$BACKUP_DIR":/backup \
  alpine tar czf /backup/downloads.tar.gz -C /data .

# å¤‡ä»½é…ç½®
docker run --rm \
  -v yt-dlp-web-deploy_config:/data \
  -v "$BACKUP_DIR":/backup \
  alpine tar czf /backup/config.tar.gz -C /data .

# å¤‡ä»½æ•°æ®åº“ï¼ˆå¦‚æœæœ‰ï¼‰
docker exec yt-dlp-web-github pg_dump -U postgres app > "$BACKUP_DIR/database.sql"

echo "å¤‡ä»½å®Œæˆ: $BACKUP_DIR"
```

#### 2. æ•°æ®æ¢å¤

```bash
#!/bin/bash
# restore.sh

BACKUP_DIR="$1"
if [ -z "$BACKUP_DIR" ]; then
    echo "ç”¨æ³•: $0 <å¤‡ä»½ç›®å½•>"
    exit 1
fi

# åœæ­¢æœåŠ¡
docker-compose -f docker-compose.github.yml down

# æ¢å¤ä¸‹è½½æ–‡ä»¶
docker run --rm \
  -v yt-dlp-web-deploy_downloads:/data \
  -v "$BACKUP_DIR":/backup \
  alpine tar xzf /backup/downloads.tar.gz -C /data

# æ¢å¤é…ç½®
docker run --rm \
  -v yt-dlp-web-deploy_config:/data \
  -v "$BACKUP_DIR":/backup \
  alpine tar xzf /backup/config.tar.gz -C /data

# å¯åŠ¨æœåŠ¡
docker-compose -f docker-compose.github.yml up -d

echo "æ¢å¤å®Œæˆ"
```

### å¥åº·æ£€æŸ¥

#### 1. åº”ç”¨å¥åº·æ£€æŸ¥

```python
# webapp/routes/health.py
from flask import Blueprint, jsonify
import psutil
import os

health_bp = Blueprint('health', __name__)

@health_bp.route('/health')
def health_check():
    try:
        # æ£€æŸ¥ yt-dlp
        import yt_dlp
        ytdlp_status = "ok"
        ytdlp_version = yt_dlp.__version__
    except:
        ytdlp_status = "error"
        ytdlp_version = "unknown"
    
    # æ£€æŸ¥ç³»ç»Ÿèµ„æº
    cpu_percent = psutil.cpu_percent()
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/app/downloads')
    
    return jsonify({
        'status': 'healthy' if ytdlp_status == 'ok' else 'unhealthy',
        'yt_dlp': {
            'status': ytdlp_status,
            'version': ytdlp_version
        },
        'system': {
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'disk_percent': (disk.used / disk.total) * 100
        }
    })
```

#### 2. å¤–éƒ¨ç›‘æ§

```bash
#!/bin/bash
# monitor.sh

URL="http://localhost:8080/health"
WEBHOOK_URL="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"

RESPONSE=$(curl -s -w "%{http_code}" "$URL")
HTTP_CODE="${RESPONSE: -3}"
BODY="${RESPONSE%???}"

if [ "$HTTP_CODE" != "200" ]; then
    MESSAGE="ğŸš¨ yt-dlp Web æœåŠ¡å¼‚å¸¸: HTTP $HTTP_CODE"
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"$MESSAGE\"}" \
        "$WEBHOOK_URL"
fi
```

### æ€§èƒ½è°ƒä¼˜

#### 1. æ•°æ®åº“ä¼˜åŒ–

```sql
-- PostgreSQL ä¼˜åŒ–
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '16MB';
SELECT pg_reload_conf();
```

#### 2. åº”ç”¨ä¼˜åŒ–

```python
# webapp/config.py
import os

class ProductionConfig:
    # æ•°æ®åº“è¿æ¥æ± 
    SQLALCHEMY_ENGINE_OPTIONS = {
        'pool_size': 20,
        'pool_recycle': 3600,
        'pool_pre_ping': True
    }
    
    # Redis ç¼“å­˜
    CACHE_TYPE = 'redis'
    CACHE_REDIS_URL = os.environ.get('REDIS_URL', 'redis://redis:6379/0')
    
    # ä¼šè¯é…ç½®
    SESSION_PERMANENT = False
    SESSION_USE_SIGNER = True
    SESSION_KEY_PREFIX = 'ytdlp:'
```

#### 3. ç³»ç»Ÿä¼˜åŒ–

```bash
# /etc/sysctl.conf
# ç½‘ç»œä¼˜åŒ–
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216

# æ–‡ä»¶æè¿°ç¬¦
fs.file-max = 65536

# åº”ç”¨åé‡å¯
sudo sysctl -p
```
